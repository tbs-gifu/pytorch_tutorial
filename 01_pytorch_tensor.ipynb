{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Pytorch tensor\n",
    "#### ＝＝＝ 目次 ＝＝＝\n",
    "0. Pytorchの呼び出し\n",
    "1. Tensorの生成\n",
    "2. 基本演算\n",
    "3. 誤差逆伝播&勾配降下法\n",
    "4. GPUの使用\n",
    "\n",
    "## Pytorchの特徴\n",
    "- Numpyに代わってGPU上で動くパッケージ\n",
    "- 柔軟性があり高速な深層学習のプラットフォーム\n",
    "- define by run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Pytorchの呼び出し\n",
    "`torch`という名前のモジュールをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Tensor(テンソル)の生成\n",
    "tensor：多次元配列のようなもの(ex. ベクトル，行列)\n",
    "\n",
    "Numpyのndarrayのようなもの(ndarrayと比べて，GPUを使うことで計算を高速化できる)\n",
    "\n",
    "|<div align='center'>関数</div>|<div align='center'>意味</div>|<div align='center'>例</div>|\n",
    "|---|---|---|\n",
    "|<div align='left'>torch.tensor(array)</div>|<div align='left'>配列をtensorに変換</div>|<div align='left'>torch.tensor([2.5, 5.0, 3.6])</div>|\n",
    "|<div align='left'>torch.empty(shape)</div>|<div align='left'>空のテンソルを作成 (何かしらの値が入っている)</div>|<div align='left'>torch.empty(2, 5)</div>|\n",
    "|<div align='left'>torch.zeros(shape)</div>|<div align='left'>0のテンソルを作成</div>|<div align='left'>torch.zeros(2, 5)</div>|\n",
    "|<div align='left'>torch.ones(shape)</div>|<div align='left'>1のテンソルを作成</div>|<div align='left'>torch.ones(2, 5)</div>|\n",
    "|<div align='left'>torch.full(shape,fill_value)</div>|<div align='left'>任意の値のテンソルを作成</div>|<div align='left'>torch.full((2, 5),fill_value=4)</div>|\n",
    "|<div align='left'>torch.zeros_like(tensor)</div>|<div align='left'>引数のテンソルと同じサイズの0のテンソルを作成</div>|<div align='left'>torch.zeros_like(a)</div>|\n",
    "|<div align='left'>torch.eye(shape)</div>|<div align='left'>単位行列を作成</div>|<div align='left'>torch.eye(3, 3)</div>|\n",
    "|<div align='left'>torch.rand(shape)</div>|<div align='left'>[0, 1]の一様分布による乱数</div>|<div align='left'>torch.rand(2, 5)</div>|\n",
    "|<div align='left'>torch.randn(shape)</div>|<div align='left'>標準正規分布による乱数</div>|<div align='left'>torch.randn(2, 5)</div>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor()`：配列をtensorに変換\n",
    "\n",
    "`dtype`で値のデータ型を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000, 2.4000])\n"
     ]
    }
   ],
   "source": [
    "# 一次元配列\n",
    "x = torch.tensor([5.5, 3, 2.4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 5., 2.],\n",
      "        [8., 8., 1.],\n",
      "        [4., 1., 5.],\n",
      "        [5., 8., 8.],\n",
      "        [2., 5., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 二次元配列\n",
    "x = torch.tensor([[3, 5, 2],\n",
    "                  [8, 8, 1],\n",
    "                  [4, 1, 5],\n",
    "                  [5, 8, 8],\n",
    "                  [2, 5, 2]], dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.rand()`：[0, 1]の一様分布による乱数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6855, 0.6594, 0.2710, 0.3844, 0.8784],\n",
      "        [0.2721, 0.9230, 0.8516, 0.2811, 0.5556]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.randn()`：標準正規分布による乱数 (平均0, 分散1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6088, -0.1886,  2.0373,  1.3687,  0.3790],\n",
      "        [ 0.0522, -1.3260, -0.5854, -1.3858, -1.2349]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## tensorのshape\n",
    "`変数.shape` or `変数.size()`：tensorのshapeを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 6)\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`変数.view()`：tensorのshapeを変更したものを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : torch.Size([4, 4])\n",
      "y : torch.Size([16])\n",
      "z : torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # -1を使うと自動で調整してくれる\n",
    "print(\"x :\", x.shape)\n",
    "print(\"y :\", y.shape)\n",
    "print(\"z :\", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## スライス\n",
    "リストやndarrayのように，スライスを用いることで一部を抽出できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6004, -1.1912,  1.4197,  0.4917, -0.4241,  0.0186],\n",
      "        [-0.9033,  0.6858,  0.7149, -1.6444, -0.2864,  0.7098],\n",
      "        [ 0.8180, -1.1578, -1.0977,  1.1387, -0.4770, -0.9827],\n",
      "        [-0.3123,  0.1478,  0.8375, -0.2153, -0.4981, -1.0739]])\n",
      "tensor([[-0.9033,  0.6858,  0.7149, -1.6444, -0.2864,  0.7098],\n",
      "        [ 0.8180, -1.1578, -1.0977,  1.1387, -0.4770, -0.9827]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 6)\n",
    "print(x)\n",
    "print(x[1:3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Numpyとの変換\n",
    "`変数.numpy()`：tensor → ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.9772, -0.2097,  0.8352],\n",
      "        [-0.3463, -1.0564,  0.2543]])\n",
      "<class 'numpy.ndarray'>\n",
      "[[-0.9771883  -0.20965306  0.8351917 ]\n",
      " [-0.34626698 -1.0563529   0.25432095]]\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(type(a))\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.from_numpy(ndarray)`：ndarray → tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'>\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "print(type(a))\n",
    "print(a)\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "print(type(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 基本演算\n",
    "\n",
    "|<div align='center'>演算</div>|<div align='center'>演算子</div>|\n",
    "|---|---|\n",
    "|<div align='center'>足し算</div>|<div align='center'>+</div>|\n",
    "|<div align='center'>アダマール積</div>|<div align='center'>*</div>|\n",
    "|<div align='center'>行列積</div>|<div align='center'>torch.mm()</div>|\n",
    "|<div align='center'>要素の和</div>|<div align='center'>torch.sum()</div>|\n",
    "|<div align='center'>要素の平均</div>|<div align='center'>torch.mean()</div>|\n",
    "|<div align='center'>要素の標準偏差</div>|<div align='center'>torch.std()</div>|\n",
    "|<div align='center'>要素の最大値</div>|<div align='center'>torch.max()</div>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テンソルの作成\n",
    "x = torch.tensor([[4., 3.], \n",
    "                  [2., 1.]])\n",
    "y = torch.tensor([[2., 2.], \n",
    "                  [1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5.],\n",
       "        [3., 2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 足し算\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 6.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# アダマール積\n",
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22., 15.],\n",
       "        [10.,  7.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行列積\n",
    "torch.mm(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要素の和\n",
    "torch.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要素の最大値\n",
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([4., 2.]),\n",
       "indices=tensor([0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 誤差逆伝播&勾配降下法\n",
    "`変数.backward()`：backpropagation(誤差逆伝播)による微分を行う．\n",
    "\n",
    "`requires_grad=True`を指定することでtensorの勾配を保持する．\n",
    "\n",
    "例.\n",
    "$$y=w^2$$\n",
    "$$\\frac{dy}{dw} = 2w$$\n",
    "$$\\frac{dy}{dw}|_{w=1.0} = 2.0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w : tensor(1., requires_grad=True)\n",
      "y : tensor(1., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "y = w * w\n",
    "print(\"w :\", w)\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wの勾配 tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# backpropagation\n",
    "y.backward()\n",
    "print(\"wの勾配\", w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizerによる勾配降下法\n",
    "backpropagationで求めた勾配を用いて，optimizerによりtensorの値を更新する(学習)\n",
    "\n",
    "例. $y=w^2$が最小となるときの$w$を勾配降下法で求める．(初期値 $w=1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 初期値1のパラメータ\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizerを定義\n",
    "# 更新するパラメータや学習率などを指定\n",
    "optimizer = optim.SGD([w], lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDによる更新を1回行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8000, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad() # 勾配を初期化\n",
    "y = w * w             # 順伝播\n",
    "y.backward()          # backpropagation\n",
    "optimizer.step()      # 勾配を元にパラメータを更新\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続けて更新を20回行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(0.6400, requires_grad=True)\n",
      "2 tensor(0.5120, requires_grad=True)\n",
      "3 tensor(0.4096, requires_grad=True)\n",
      "4 tensor(0.3277, requires_grad=True)\n",
      "5 tensor(0.2621, requires_grad=True)\n",
      "6 tensor(0.2097, requires_grad=True)\n",
      "7 tensor(0.1678, requires_grad=True)\n",
      "8 tensor(0.1342, requires_grad=True)\n",
      "9 tensor(0.1074, requires_grad=True)\n",
      "10 tensor(0.0859, requires_grad=True)\n",
      "11 tensor(0.0687, requires_grad=True)\n",
      "12 tensor(0.0550, requires_grad=True)\n",
      "13 tensor(0.0440, requires_grad=True)\n",
      "14 tensor(0.0352, requires_grad=True)\n",
      "15 tensor(0.0281, requires_grad=True)\n",
      "16 tensor(0.0225, requires_grad=True)\n",
      "17 tensor(0.0180, requires_grad=True)\n",
      "18 tensor(0.0144, requires_grad=True)\n",
      "19 tensor(0.0115, requires_grad=True)\n",
      "20 tensor(0.0092, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 20回パラメータを更新\n",
    "for i in range(1, 21):\n",
    "    optimizer.zero_grad() # 勾配を初期化\n",
    "    y = w * w             # 順伝播\n",
    "    y.backward()          # backpropagation\n",
    "    optimizer.step()      # 勾配を元にパラメータを更新\n",
    "\n",
    "    print(i, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=w^2$が最小となるときの$w$に近づいてることが分かる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. GPUの使用\n",
    "`torch.cuda.is_available()`：GPU(cuda)が使用できる場合`True`を，できない場合`False`を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用しているデバイスをdeviceに代入する\n",
    "\n",
    "cudaが使用可能であれば`\"cuda:0\"`，そうでなければ`\"cpu\"`を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`変数.to(device)`：変数をデバイス(cuda or cpu)に渡す\n",
    "\n",
    "これによりデバイス上で計算が可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0784,  1.9486,  0.4547, -2.0565])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4)\n",
    "y = torch.randn(4)\n",
    "\n",
    "# tensorをGPUへ\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "z = x + y # GPU上で計算が行われる\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数をCPUに渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0784,  1.9486,  0.4547, -2.0565])\n"
     ]
    }
   ],
   "source": [
    "z = z.to(\"cpu\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## マルチGPUの使用について\n",
    "GPUが複数使用できる場合，`torch.nn.DataParallel`をモデルに適用することで並列計算が行える．\n",
    "\n",
    "使用できるGPUの個数は`torch.cuda.device_count()`で確認できる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netを定義した後に記述\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net = nn.DataParallel(net)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークについては`02_pytorch_network.ipynb`で説明する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
